{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ TEMPORAL: Time-Embedded Tokens for Experiential Learning\n",
    "\n",
    "**One-Click Execution on Google Colab or Kaggle**\n",
    "\n",
    "This notebook trains and evaluates the TEMPORAL architecture - a novel approach that uses time-embedded tokens for experiential learning.\n",
    "\n",
    "## Quick Start\n",
    "Just run all cells in order! ‚ñ∂Ô∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/PlanetDestroyyer/TEMPORAL.git\n",
    "%cd TEMPORAL/temporal_prototype\n",
    "\n",
    "print(\"‚úÖ Repository cloned!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch numpy matplotlib seaborn scipy tqdm datasets transformers\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check syntax\n",
    "!python check_syntax.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run Quick Tests (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run unit tests to verify everything works\n",
    "!python test_implementation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Train Models\n",
    "\n",
    "‚è±Ô∏è This takes 10-20 minutes on GPU, 30-60 minutes on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train both TEMPORAL and Baseline models\n",
    "!python train.py --model both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and compare both models\n",
    "!python evaluate.py --model both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all plots\n",
    "!python visualize.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation results\n",
    "import json\n",
    "\n",
    "with open('outputs/evaluation_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'temporal' in results:\n",
    "    print(f\"\\nüîµ TEMPORAL:\")\n",
    "    print(f\"  Test Perplexity: {results['temporal']['test_perplexity']:.4f}\")\n",
    "    if 'time_frequency_correlation' in results['temporal']:\n",
    "        print(f\"  Time-Freq Correlation: {results['temporal']['time_frequency_correlation']:.4f}\")\n",
    "    if 'confidence_time_correlation' in results['temporal']:\n",
    "        print(f\"  Confidence-Time Correlation: {results['temporal']['confidence_time_correlation']:.4f}\")\n",
    "\n",
    "if 'baseline' in results:\n",
    "    print(f\"\\nüü† BASELINE:\")\n",
    "    print(f\"  Test Perplexity: {results['baseline']['test_perplexity']:.4f}\")\n",
    "\n",
    "if 'temporal' in results and 'baseline' in results:\n",
    "    t_ppl = results['temporal']['test_perplexity']\n",
    "    b_ppl = results['baseline']['test_perplexity']\n",
    "    improvement = ((b_ppl - t_ppl) / b_ppl) * 100\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    if improvement > 0:\n",
    "        print(f\"‚úÖ TEMPORAL is BETTER by {improvement:.2f}%\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  BASELINE is better by {-improvement:.2f}%\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Display Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the main summary plot\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "plots = [\n",
    "    'summary_analysis.png',\n",
    "    'time_evolution.png',\n",
    "    'frequency_vs_time.png',\n",
    "    'perplexity_comparison.png',\n",
    "    'token_category_analysis.png'\n",
    "]\n",
    "\n",
    "for plot in plots:\n",
    "    plot_path = f'outputs/plots/{plot}'\n",
    "    if os.path.exists(plot_path):\n",
    "        print(f\"\\nüìä {plot}\")\n",
    "        print(\"=\"*60)\n",
    "        display(Image(filename=plot_path))\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {plot} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Complete!\n",
    "\n",
    "### What Just Happened?\n",
    "\n",
    "You trained and evaluated a novel neural architecture that:\n",
    "- Uses **time-embedded tokens** [content | time]\n",
    "- Learns through **experience** (usage-based updates)\n",
    "- Demonstrates **epistemic awareness** (knows what it knows)\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Time embeddings grow with usage** - frequent tokens have high time values\n",
    "2. **Model performs better on experienced tokens** - experiential learning works!\n",
    "3. **Confidence correlates with experience** - epistemic self-awareness\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Review the plots above\n",
    "- Check `outputs/evaluation_results.json` for detailed metrics\n",
    "- Modify `config.py` to experiment with different settings\n",
    "- Read `ANALYSIS.md` for interpretation guidance\n",
    "\n",
    "---\n",
    "\n",
    "**Dataset Used**: WikiText-2 (via HuggingFace datasets)\n",
    "\n",
    "**Model Size**: ~10M parameters\n",
    "\n",
    "**Architecture**: 2-layer transformer with time-aware attention"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
